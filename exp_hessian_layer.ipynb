{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b447e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pprint\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" # Set GPU Index to use\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformer import BertForSequenceClassification,WEIGHTS_NAME, CONFIG_NAME\n",
    "from transformer.modeling_quant import BertForSequenceClassification as QuantBertForSequenceClassification\n",
    "from transformer import BertTokenizer\n",
    "from transformer import BertAdam\n",
    "from transformer import BertConfig\n",
    "from transformer import QuantizeLinear, QuantizeAct, BertSelfAttention, FP_BertSelfAttention, ClipLinear, BertAttention, FP_BertAttention\n",
    "from utils_glue import *\n",
    "from bertviz import model_view\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0 \n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def do_eval(model, task_name, eval_dataloader,\n",
    "            device, output_mode, eval_labels, num_labels, teacher_model=None):\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "\n",
    "    for batch_ in tqdm(eval_dataloader, desc=\"Inference\"):\n",
    "        batch_ = tuple(t.to(device) for t in batch_)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
    "\n",
    "            # teacher attnmap test\n",
    "            if teacher_model is not None:\n",
    "                \n",
    "                # logits, _, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids, segment_ids, input_mask)\n",
    "                \n",
    "                # # logits, _, _, _, _ = model(input_ids, segment_ids, input_mask, teacher_probs=teacher_probs)\n",
    "                # logits, _, _, _, _ = model(input_ids, segment_ids, input_mask, teacher_probs=(teacher_probs, teacher_values, teacher_reps))\n",
    "                teacher_logits, teacher_atts, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids, segment_ids, input_mask)\n",
    "                logits, student_atts, student_reps, student_probs, student_values  = model(input_ids, segment_ids, input_mask, teacher_outputs=(teacher_probs, teacher_values, teacher_reps, teacher_logits, teacher_atts))\n",
    "            else:\n",
    "                logits, _, _, _, _ = model(input_ids, segment_ids, input_mask)\n",
    "        \n",
    "        # create eval loss and other metric required by the task\n",
    "        if output_mode == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif output_mode == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(\n",
    "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    preds = preds[0]\n",
    "    if output_mode == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif output_mode == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result = compute_metrics(task_name, preds, eval_labels.numpy())\n",
    "    result['eval_loss'] = eval_loss\n",
    "    return result\n",
    "\n",
    "processors = {\n",
    "    \"cola\": ColaProcessor,\n",
    "    \"mnli\": MnliProcessor,\n",
    "    \"mnli-mm\": MnliMismatchedProcessor,\n",
    "    \"mrpc\": MrpcProcessor,\n",
    "    \"sst-2\": Sst2Processor,\n",
    "    \"sts-b\": StsbProcessor,\n",
    "    \"qqp\": QqpProcessor,\n",
    "    \"qnli\": QnliProcessor,\n",
    "    \"rte\": RteProcessor   \n",
    "}\n",
    "\n",
    "output_modes = {\n",
    "        \"cola\": \"classification\",\n",
    "        \"mnli\": \"classification\",\n",
    "        \"mrpc\": \"classification\",\n",
    "        \"sst-2\": \"classification\",\n",
    "        \"sts-b\": \"regression\",\n",
    "        \"qqp\": \"classification\",\n",
    "        \"qnli\": \"classification\",\n",
    "        \"rte\": \"classification\"\n",
    "}\n",
    "\n",
    "default_params = {\n",
    "        \"cola\": {\"max_seq_length\": 64,\"batch_size\":16,\"eval_step\": 400}, # No Aug : 50 Aug : 400\n",
    "        \"mnli\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":8000},\n",
    "        \"mrpc\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":20},\n",
    "        \"sst-2\": {\"max_seq_length\": 64,\"batch_size\":32,\"eval_step\":100},\n",
    "        \"sts-b\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":100},\n",
    "        \"qqp\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":1000},\n",
    "        \"qnli\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":1000},\n",
    "        \"rte\": {\"max_seq_length\": 128,\"batch_size\":32,\"eval_step\":100}\n",
    "    }\n",
    "\n",
    "def get_tensor_data(output_mode, features):\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "\n",
    "    all_seq_lengths = torch.tensor([f.seq_length for f in features], dtype=torch.long)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    tensor_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label_ids, all_seq_lengths)\n",
    "    return tensor_data, all_label_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec38c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def group_product(xs, ys):\n",
    "    \"\"\"\n",
    "    the inner product of two lists of variables xs,ys\n",
    "    :param xs:\n",
    "    :param ys:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return sum([torch.sum(x * y) for (x, y) in zip(xs, ys)])\n",
    "\n",
    "\n",
    "def de_variable(v):\n",
    "    '''\n",
    "    normalize the vector and detach it from variable\n",
    "    '''\n",
    "\n",
    "    s = group_product(v, v)\n",
    "    s = s**0.5\n",
    "    s = s.cpu().item() + 1e-6\n",
    "    v = [vi / s for vi in v]\n",
    "    return v\n",
    "\n",
    "def group_add(params, update, alpha=1):\n",
    "    \"\"\"\n",
    "    params = params + update*alpha\n",
    "    :param params: list of variable\n",
    "    :param update: list of data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for i, p in enumerate(params):\n",
    "        params[i].data.add_(update[i] * alpha)\n",
    "    return params\n",
    "\n",
    "\n",
    "def normalization(v):\n",
    "    \"\"\"\n",
    "    normalization of a list of vectors\n",
    "    return: normalized vectors v\n",
    "    \"\"\"\n",
    "    s = group_product(v, v)\n",
    "    s = s**0.5\n",
    "    s = s.cpu().item()\n",
    "    v = [vi / (s + 1e-6) for vi in v]\n",
    "    # v = [vi / s for vi in v]\n",
    "    return v\n",
    "\n",
    "\n",
    "def orthonormal(w, v_list):\n",
    "    for v in v_list:\n",
    "        w = group_add(w, v, alpha=-group_product(w, v))\n",
    "    return normalization(w)\n",
    "\n",
    "\n",
    "def total_number_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])\n",
    "\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6460b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"cola\"\n",
    "bert_size = \"base\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    layer_num = 24\n",
    "    head_num = 16\n",
    "else: \n",
    "    layer_num = 12\n",
    "    head_num = 12\n",
    "    \n",
    "teacher_model = None\n",
    "# torch.cuda.empty_cache()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084fe35",
   "metadata": {},
   "source": [
    "# DEVICE / DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5214fdf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 04:30:21 PM Writing example 0 of 8551\n",
      "07/14 04:30:21 PM *** Example ***\n",
      "07/14 04:30:21 PM guid: train-0\n",
      "07/14 04:30:21 PM tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]\n",
      "07/14 04:30:21 PM input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:21 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:21 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:21 PM label: 1\n",
      "07/14 04:30:21 PM label_id: 1\n",
      "07/14 04:30:22 PM Writing example 0 of 1043\n",
      "07/14 04:30:22 PM *** Example ***\n",
      "07/14 04:30:22 PM guid: dev-0\n",
      "07/14 04:30:22 PM tokens: [CLS] the sailors rode the breeze clear of the rocks . [SEP]\n",
      "07/14 04:30:22 PM input_ids: 101 1996 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:22 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:22 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "07/14 04:30:22 PM label: 1\n",
      "07/14 04:30:22 PM label_id: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"models\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    model_dir = os.path.join(model_dir, \"BERT_large\")\n",
    "    output_dir = os.path.join(output_dir, \"BERT_large\")\n",
    "\n",
    "teacher_model_dir = os.path.join(model_dir,task_name)\n",
    "\n",
    "# Processor & Task Info\n",
    "processor = processors[task_name]()\n",
    "output_mode = output_modes[task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "\n",
    "if task_name in default_params:\n",
    "    batch_size = default_params[task_name][\"batch_size\"]\n",
    "    max_seq_length = default_params[task_name][\"max_seq_length\"]\n",
    "    eval_step = default_params[task_name][\"eval_step\"]\n",
    "    \n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(teacher_model_dir, do_lower_case=True)\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "data_dir = os.path.join(\"data\",task_name)\n",
    "processed_data_dir = os.path.join(data_dir,'preprocessed')\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "train_features = convert_examples_to_features(train_examples, label_list,\n",
    "                                max_seq_length, tokenizer, output_mode)\n",
    "\n",
    "len_train_data = int(len(train_features) * 1)\n",
    "train_features = train_features[:len_train_data]\n",
    "\n",
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
    "# dev_file = train_file = os.path.join(processed_data_dir,'dev.pkl') \n",
    "# eval_features = pickle.load(open(dev_file,'rb'))\n",
    "\n",
    "train_data, train_labels = get_tensor_data(output_mode, train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "eval_data, eval_labels = get_tensor_data(\"classification\", eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=1)\n",
    "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
    "\n",
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "\n",
    "# Sampling Sentence \n",
    "i = 0 \n",
    "# num = 3\n",
    "num = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054111a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 04:30:27 PM loading configuration file output/cola/exploration/1SB_M/config.json\n",
      "07/14 04:30:29 PM Loading model output/cola/exploration/1SB_M/pytorch_model.bin\n",
      "07/14 04:30:29 PM loading model...\n",
      "07/14 04:30:29 PM done!\n",
      "07/14 04:30:29 PM Weights from pretrained model not used in BertForSequenceClassification: ['bert.embeddings.word_embeddings.qweight', 'bert.encoder.layer.0.attention.self.query.qweight', 'bert.encoder.layer.0.attention.self.key.qweight', 'bert.encoder.layer.0.attention.self.value.qweight', 'bert.encoder.layer.0.attention.output.dense.qweight', 'bert.encoder.layer.0.intermediate.dense.qweight', 'bert.encoder.layer.0.output.dense.qweight', 'bert.encoder.layer.1.attention.self.query.qweight', 'bert.encoder.layer.1.attention.self.key.qweight', 'bert.encoder.layer.1.attention.self.value.qweight', 'bert.encoder.layer.1.attention.output.dense.qweight', 'bert.encoder.layer.1.intermediate.dense.qweight', 'bert.encoder.layer.1.output.dense.qweight', 'bert.encoder.layer.2.attention.self.query.qweight', 'bert.encoder.layer.2.attention.self.key.qweight', 'bert.encoder.layer.2.attention.self.value.qweight', 'bert.encoder.layer.2.attention.output.dense.qweight', 'bert.encoder.layer.2.intermediate.dense.qweight', 'bert.encoder.layer.2.output.dense.qweight', 'bert.encoder.layer.3.attention.self.query.qweight', 'bert.encoder.layer.3.attention.self.key.qweight', 'bert.encoder.layer.3.attention.self.value.qweight', 'bert.encoder.layer.3.attention.output.dense.qweight', 'bert.encoder.layer.3.intermediate.dense.qweight', 'bert.encoder.layer.3.output.dense.qweight', 'bert.encoder.layer.4.attention.self.query.qweight', 'bert.encoder.layer.4.attention.self.key.qweight', 'bert.encoder.layer.4.attention.self.value.qweight', 'bert.encoder.layer.4.attention.output.dense.qweight', 'bert.encoder.layer.4.intermediate.dense.qweight', 'bert.encoder.layer.4.output.dense.qweight', 'bert.encoder.layer.5.attention.self.query.qweight', 'bert.encoder.layer.5.attention.self.key.qweight', 'bert.encoder.layer.5.attention.self.value.qweight', 'bert.encoder.layer.5.attention.output.dense.qweight', 'bert.encoder.layer.5.intermediate.dense.qweight', 'bert.encoder.layer.5.output.dense.qweight', 'bert.encoder.layer.6.attention.self.query.qweight', 'bert.encoder.layer.6.attention.self.key.qweight', 'bert.encoder.layer.6.attention.self.value.qweight', 'bert.encoder.layer.6.attention.output.dense.qweight', 'bert.encoder.layer.6.intermediate.dense.qweight', 'bert.encoder.layer.6.output.dense.qweight', 'bert.encoder.layer.7.attention.self.query.qweight', 'bert.encoder.layer.7.attention.self.key.qweight', 'bert.encoder.layer.7.attention.self.value.qweight', 'bert.encoder.layer.7.attention.output.dense.qweight', 'bert.encoder.layer.7.intermediate.dense.qweight', 'bert.encoder.layer.7.output.dense.qweight', 'bert.encoder.layer.8.attention.self.query.qweight', 'bert.encoder.layer.8.attention.self.key.qweight', 'bert.encoder.layer.8.attention.self.value.qweight', 'bert.encoder.layer.8.attention.output.dense.qweight', 'bert.encoder.layer.8.intermediate.dense.qweight', 'bert.encoder.layer.8.output.dense.qweight', 'bert.encoder.layer.9.attention.self.query.qweight', 'bert.encoder.layer.9.attention.self.key.qweight', 'bert.encoder.layer.9.attention.self.value.qweight', 'bert.encoder.layer.9.attention.output.dense.qweight', 'bert.encoder.layer.9.intermediate.dense.qweight', 'bert.encoder.layer.9.output.dense.qweight', 'bert.encoder.layer.10.attention.self.query.qweight', 'bert.encoder.layer.10.attention.self.key.qweight', 'bert.encoder.layer.10.attention.self.value.qweight', 'bert.encoder.layer.10.attention.output.dense.qweight', 'bert.encoder.layer.10.intermediate.dense.qweight', 'bert.encoder.layer.10.output.dense.qweight', 'bert.encoder.layer.11.attention.self.query.qweight', 'bert.encoder.layer.11.attention.self.key.qweight', 'bert.encoder.layer.11.attention.self.value.qweight', 'bert.encoder.layer.11.attention.output.dense.qweight', 'bert.encoder.layer.11.intermediate.dense.qweight', 'bert.encoder.layer.11.output.dense.qweight', 'bert.pooler.dense.qweight']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# teacher_model = BertForSequenceClassification.from_pretrained(teacher_model_dir, num_labels=num_labels)\n",
    "# teacher_model.to(device)\n",
    "# teacher_model.eval()\n",
    "\n",
    "st_model_name = \"1SB_M\"\n",
    "student_model_dir = os.path.join(output_dir, task_name, \"exploration\", st_model_name)   \n",
    "student_config = BertConfig.from_pretrained(student_model_dir)   \n",
    "student_model = QuantBertForSequenceClassification.from_pretrained(student_model_dir, config = student_config, num_labels=num_labels)\n",
    "student_model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1a3674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_index: 5.344375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_percentage = 0.01\n",
    "\n",
    "percentage_index = len(train_dataloader.dataset) * data_percentage / batch_size\n",
    "print(f'percentage_index: {percentage_index}')\n",
    "\n",
    "student_model.eval()\n",
    "\n",
    "csv_path = os.path.join(f\"{task_name}-{data_percentage}-eigens.csv\")\n",
    "csv_file = open(csv_path, 'w', newline='')\n",
    "writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "writer.writerow(['block', 'iters', 'max_eigenvalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2a4e568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 04:50:40 PM block_id: 0\n",
      "07/14 04:50:42 PM block_0-lambda: -3.2217998176102134e-06\n",
      "07/14 04:50:44 PM block_0-lambda: 0.0024439981563399928\n",
      "07/14 04:50:46 PM block_0-lambda: -0.0018867165104657804\n",
      "07/14 04:50:48 PM block_0-lambda: 0.1748031934734367\n",
      "07/14 04:50:49 PM block_0-lambda: 2.047457364327363\n",
      "07/14 04:50:51 PM block_0-lambda: 0.32649800284203556\n",
      "07/14 04:50:53 PM block_0-lambda: 0.7467861664028923\n",
      "07/14 04:50:55 PM block_0-lambda: 0.5070455812345596\n",
      "07/14 04:50:57 PM block_0-lambda: 0.10828334481350066\n",
      "07/14 04:50:59 PM block_0-lambda: 0.2158531792999471\n",
      "07/14 04:51:01 PM block_0-lambda: 0.12523935295910657\n",
      "07/14 04:51:03 PM block_0-lambda: 0.2529545341119642\n",
      "07/14 04:51:05 PM block_0-lambda: 0.36685967247411666\n",
      "07/14 04:51:07 PM block_0-lambda: 0.28622555545917966\n",
      "07/14 04:51:08 PM block_0-lambda: 0.4682571006063801\n",
      "07/14 04:51:10 PM block_0-lambda: 0.6783965093715053\n",
      "07/14 04:51:12 PM block_0-lambda: 0.21550128674900276\n",
      "07/14 04:51:14 PM block_0-lambda: 0.13486297628835214\n",
      "07/14 04:51:16 PM block_0-lambda: 0.19389511534880788\n",
      "07/14 04:51:18 PM block_0-lambda: 0.14880614982768256\n",
      "07/14 04:51:20 PM block_0-lambda: 0.21283396530285198\n",
      "07/14 04:51:22 PM block_0-lambda: 0.2962709546660752\n",
      "07/14 04:51:24 PM block_0-lambda: 0.5666033508707634\n",
      "07/14 04:51:26 PM block_0-lambda: 0.2848442165966745\n",
      "07/14 04:51:27 PM block_0-lambda: 0.20542407981025837\n",
      "07/14 04:51:29 PM block_0-lambda: 0.2922997615753092\n",
      "07/14 04:51:31 PM block_0-lambda: 0.09075562837681231\n",
      "07/14 04:51:33 PM block_0-lambda: 0.06129881914924173\n",
      "07/14 04:51:35 PM block_0-lambda: 0.27638518898100367\n",
      "07/14 04:51:37 PM block_0-lambda: 0.26272570873586604\n",
      "07/14 04:51:39 PM block_0-lambda: 0.08360506735159184\n",
      "07/14 04:51:41 PM block_0-lambda: 0.060077310793442466\n",
      "07/14 04:51:43 PM block_0-lambda: 0.4891700820467818\n",
      "07/14 04:51:45 PM block_0-lambda: 0.2543057604653558\n",
      "07/14 04:51:46 PM block_0-lambda: 0.6249586722541588\n",
      "07/14 04:51:48 PM block_0-lambda: 0.39010309445315694\n",
      "07/14 04:51:50 PM block_0-lambda: 0.5265252964634071\n",
      "07/14 04:51:52 PM block_0-lambda: 0.3134122885761031\n",
      "07/14 04:51:54 PM block_0-lambda: 0.3306926530559862\n",
      "07/14 04:51:56 PM block_0-lambda: 0.7834318408825539\n",
      "07/14 04:51:58 PM block_0-lambda: 0.4215340407434757\n",
      "07/14 04:52:00 PM block_0-lambda: 0.22927941028004764\n",
      "07/14 04:52:02 PM block_0-lambda: 0.18432014045095235\n",
      "07/14 04:52:03 PM block_0-lambda: 0.34062768434059015\n",
      "07/14 04:52:05 PM block_0-lambda: 0.48169298989495923\n",
      "07/14 04:52:07 PM block_0-lambda: 0.4086863491329139\n",
      "07/14 04:52:09 PM block_0-lambda: 0.28106944628757785\n",
      "07/14 04:52:11 PM block_0-lambda: 0.5819858019706896\n",
      "07/14 04:52:13 PM block_0-lambda: 0.46358073946886236\n",
      "07/14 04:52:15 PM block_0-lambda: 0.6688094448588797\n",
      "07/14 04:52:17 PM block_0-lambda: 0.16322046145404684\n",
      "07/14 04:52:19 PM block_0-lambda: 0.3038076695859425\n",
      "07/14 04:52:21 PM block_0-lambda: 0.35165716034531547\n",
      "07/14 04:52:23 PM block_0-lambda: 2.582477332695006\n",
      "07/14 04:52:24 PM block_0-lambda: 0.21384460802538854\n",
      "07/14 04:52:26 PM block_0-lambda: 0.8024248487418777\n",
      "07/14 04:52:28 PM block_0-lambda: 0.19313514253546962\n",
      "07/14 04:52:30 PM block_0-lambda: 0.3806236765842217\n",
      "07/14 04:52:32 PM block_0-lambda: 0.23723098635324996\n",
      "07/14 04:52:34 PM block_0-lambda: 0.828332045582662\n",
      "07/14 04:52:36 PM block_0-lambda: 0.6125128376541075\n",
      "07/14 04:52:38 PM block_0-lambda: 0.3469745090392274\n",
      "07/14 04:52:40 PM block_0-lambda: 0.08253770716050092\n",
      "07/14 04:52:42 PM block_0-lambda: -0.003706029445410416\n",
      "07/14 04:52:43 PM block_0-lambda: -0.020650386419955393\n",
      "07/14 04:52:45 PM block_0-lambda: 0.030107850039190694\n",
      "07/14 04:52:47 PM block_0-lambda: 0.19762487303317045\n",
      "07/14 04:52:49 PM block_0-lambda: 0.4764225870220999\n",
      "07/14 04:52:51 PM block_0-lambda: 0.06741444111818347\n",
      "07/14 04:52:53 PM block_0-lambda: 0.2593112624802654\n",
      "07/14 04:52:55 PM block_0-lambda: 0.3729079149157216\n",
      "07/14 04:52:57 PM block_0-lambda: 0.7770746664030066\n",
      "07/14 04:52:59 PM block_0-lambda: 0.4059369209119136\n",
      "07/14 04:53:01 PM block_0-lambda: 0.720273908878987\n",
      "07/14 04:53:02 PM block_0-lambda: 0.33631193722887853\n",
      "07/14 04:53:04 PM block_0-lambda: 0.3113142273855717\n",
      "07/14 04:53:06 PM block_0-lambda: 0.5037631392966877\n",
      "07/14 04:53:08 PM block_0-lambda: 0.08843746147383277\n",
      "07/14 04:53:10 PM block_0-lambda: 0.15941338153794946\n",
      "07/14 04:53:12 PM block_0-lambda: 0.8032464072127438\n",
      "07/14 04:53:14 PM block_0-lambda: 0.3988528973790529\n",
      "07/14 04:53:16 PM block_0-lambda: 0.5212726934292681\n",
      "07/14 04:53:18 PM block_0-lambda: 0.9531836832577604\n",
      "07/14 04:53:20 PM block_0-lambda: 0.5845549566371303\n",
      "07/14 04:53:21 PM block_0-lambda: 0.29065434716065963\n",
      "07/14 04:53:23 PM block_0-lambda: 3.2000758831660767\n",
      "07/14 04:53:25 PM block_0-lambda: 0.12991732009711035\n",
      "07/14 04:53:27 PM block_0-lambda: 0.37972132736668224\n",
      "07/14 04:53:29 PM block_0-lambda: 0.2868587211508065\n",
      "07/14 04:53:31 PM block_0-lambda: 0.022464684611411836\n",
      "07/14 04:53:33 PM block_0-lambda: 0.023374548015253207\n",
      "07/14 04:53:35 PM block_0-lambda: 0.12882126937650293\n",
      "07/14 04:53:37 PM block_0-lambda: 0.1629155667228819\n",
      "07/14 04:53:39 PM block_0-lambda: 0.22629015265312993\n",
      "07/14 04:53:40 PM block_0-lambda: 0.4025972875122884\n",
      "07/14 04:53:42 PM block_0-lambda: 0.47071990235174427\n",
      "07/14 04:53:44 PM block_0-lambda: 0.41364434030011105\n",
      "07/14 04:53:46 PM block_0-lambda: 0.4186169639161812\n",
      "07/14 04:53:48 PM block_0-lambda: 0.17048288487423344\n",
      "07/14 04:53:50 PM block_0-lambda: 0.021172856576344296\n",
      "07/14 04:53:52 PM block_0-lambda: 0.07035346104239681\n",
      "07/14 04:53:54 PM block_0-lambda: 0.3740560937354389\n",
      "07/14 04:53:56 PM block_0-lambda: 0.6769238961480427\n",
      "07/14 04:53:58 PM block_0-lambda: 0.5299992985703654\n",
      "07/14 04:54:00 PM block_0-lambda: 0.2632216059970599\n",
      "07/14 04:54:01 PM block_0-lambda: -0.06809356742094251\n",
      "07/14 04:54:03 PM block_0-lambda: -0.009137707110134959\n",
      "07/14 04:54:05 PM block_0-lambda: 0.11169338572054574\n",
      "07/14 04:54:07 PM block_0-lambda: 0.23988815876855135\n",
      "07/14 04:54:09 PM block_0-lambda: 0.5957003769547238\n",
      "07/14 04:54:11 PM block_0-lambda: 0.42847981440116195\n",
      "07/14 04:54:13 PM block_0-lambda: 0.18342671345833544\n",
      "07/14 04:54:15 PM block_0-lambda: 0.5197768378098824\n",
      "07/14 04:54:17 PM block_0-lambda: 0.5461177440041506\n",
      "07/14 04:54:19 PM block_0-lambda: 0.32460704879751817\n",
      "07/14 04:54:20 PM block_0-lambda: 0.5463639974120122\n",
      "07/14 04:54:22 PM block_0-lambda: 0.4401522259338043\n",
      "07/14 04:54:24 PM block_0-lambda: 1.2566518398798385\n",
      "07/14 04:54:26 PM block_0-lambda: 0.19056971289793406\n",
      "07/14 04:54:28 PM block_0-lambda: 0.454405123358539\n",
      "07/14 04:54:30 PM block_0-lambda: 0.2880312130334377\n",
      "07/14 04:54:32 PM block_0-lambda: 0.29033015811809976\n",
      "07/14 04:54:32 PM block_id: 1\n",
      "07/14 04:54:34 PM block_1-lambda: 3.897321811606976e-06\n",
      "07/14 04:54:36 PM block_1-lambda: 0.0042515015158788765\n",
      "07/14 04:54:37 PM block_1-lambda: 0.045844195614278195\n",
      "07/14 04:54:39 PM block_1-lambda: 0.1905464258908863\n",
      "07/14 04:54:41 PM block_1-lambda: 0.7203675922406736\n",
      "07/14 04:54:43 PM block_1-lambda: 1.3643803895948756\n",
      "07/14 04:54:45 PM block_1-lambda: 0.655787056084335\n",
      "07/14 04:54:47 PM block_1-lambda: 0.6374066481881916\n",
      "07/14 04:54:48 PM block_1-lambda: 0.6463371261687686\n",
      "07/14 04:54:50 PM block_1-lambda: 1.0462469503121437\n",
      "07/14 04:54:52 PM block_1-lambda: 0.9069474645977535\n",
      "07/14 04:54:54 PM block_1-lambda: 0.915473096622471\n",
      "07/14 04:54:54 PM block_id: 2\n",
      "07/14 04:54:56 PM block_2-lambda: -1.3781597317415237e-05\n",
      "07/14 04:54:58 PM block_2-lambda: 0.0008819128787806125\n",
      "07/14 04:54:59 PM block_2-lambda: 0.11342410775823573\n",
      "07/14 04:55:01 PM block_2-lambda: 1.4362090290004002\n",
      "07/14 04:55:03 PM block_2-lambda: 1.0884313189680848\n",
      "07/14 04:55:05 PM block_2-lambda: 0.7230053588167684\n",
      "07/14 04:55:06 PM block_2-lambda: 1.0107950249159912\n",
      "07/14 04:55:08 PM block_2-lambda: 0.7301815935442035\n",
      "07/14 04:55:10 PM block_2-lambda: 0.7390013467134919\n",
      "07/14 04:55:12 PM block_2-lambda: 0.3474878938612694\n",
      "07/14 04:55:14 PM block_2-lambda: 0.7199140309367371\n",
      "07/14 04:55:15 PM block_2-lambda: 0.6203681875315205\n",
      "07/14 04:55:17 PM block_2-lambda: 0.2309155009696531\n",
      "07/14 04:55:19 PM block_2-lambda: 0.3112014727681133\n",
      "07/14 04:55:21 PM block_2-lambda: 0.2058504506337435\n",
      "07/14 04:55:22 PM block_2-lambda: 0.11421877687374146\n",
      "07/14 04:55:24 PM block_2-lambda: 1.5619188062685467\n",
      "07/14 04:55:26 PM block_2-lambda: 0.877659636733825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 04:55:28 PM block_2-lambda: 0.840804066912861\n",
      "07/14 04:55:30 PM block_2-lambda: 0.7001804784088438\n",
      "07/14 04:55:31 PM block_2-lambda: 0.8907316776900636\n",
      "07/14 04:55:33 PM block_2-lambda: 0.49316915709043074\n",
      "07/14 04:55:35 PM block_2-lambda: 1.0273064943576133\n",
      "07/14 04:55:37 PM block_2-lambda: 0.19774853507059664\n",
      "07/14 04:55:38 PM block_2-lambda: 0.15136005864228688\n",
      "07/14 04:55:40 PM block_2-lambda: 0.6295960432687652\n",
      "07/14 04:55:42 PM block_2-lambda: 0.29299549436920524\n",
      "07/14 04:55:44 PM block_2-lambda: 0.6498577915120718\n",
      "07/14 04:55:46 PM block_2-lambda: 0.06491550993827362\n",
      "07/14 04:55:47 PM block_2-lambda: 0.10134486507468858\n",
      "07/14 04:55:49 PM block_2-lambda: 0.42918239500268607\n",
      "07/14 04:55:51 PM block_2-lambda: 0.8522931267233456\n",
      "07/14 04:55:53 PM block_2-lambda: 0.10508586476245353\n",
      "07/14 04:55:54 PM block_2-lambda: 0.6211146654796633\n",
      "07/14 04:55:56 PM block_2-lambda: 0.5331880571465508\n",
      "07/14 04:55:58 PM block_2-lambda: 0.7981291543306794\n",
      "07/14 04:56:00 PM block_2-lambda: 1.877108357438092\n",
      "07/14 04:56:02 PM block_2-lambda: 2.530603695439952\n",
      "07/14 04:56:03 PM block_2-lambda: 1.988203262616397\n",
      "07/14 04:56:05 PM block_2-lambda: 0.7436428665626873\n",
      "07/14 04:56:07 PM block_2-lambda: 0.6892299194835582\n",
      "07/14 04:56:09 PM block_2-lambda: 0.4948712499389006\n",
      "07/14 04:56:10 PM block_2-lambda: 1.3860754932719856\n",
      "07/14 04:56:12 PM block_2-lambda: 1.2929853703205856\n",
      "07/14 04:56:14 PM block_2-lambda: 0.44025460846479025\n",
      "07/14 04:56:16 PM block_2-lambda: 0.7227224350644752\n",
      "07/14 04:56:18 PM block_2-lambda: 0.6177018698356734\n",
      "07/14 04:56:19 PM block_2-lambda: 1.4859238447132004\n",
      "07/14 04:56:21 PM block_2-lambda: 1.26035063744372\n",
      "07/14 04:56:23 PM block_2-lambda: 1.9661807132846303\n",
      "07/14 04:56:25 PM block_2-lambda: 1.3809177334887732\n",
      "07/14 04:56:26 PM block_2-lambda: 0.9092464542935402\n",
      "07/14 04:56:28 PM block_2-lambda: 1.2033723276437422\n",
      "07/14 04:56:30 PM block_2-lambda: 0.2795491660774667\n",
      "07/14 04:56:32 PM block_2-lambda: 0.16145977189339833\n",
      "07/14 04:56:34 PM block_2-lambda: 0.810172016642105\n",
      "07/14 04:56:35 PM block_2-lambda: 0.5756879602868771\n",
      "07/14 04:56:37 PM block_2-lambda: 0.8532882224689546\n",
      "07/14 04:56:39 PM block_2-lambda: 1.0463304623374183\n",
      "07/14 04:56:41 PM block_2-lambda: 1.3068251687314074\n",
      "07/14 04:56:42 PM block_2-lambda: 1.339975249319798\n",
      "07/14 04:56:44 PM block_2-lambda: 1.2918587609796186\n",
      "07/14 04:56:46 PM block_2-lambda: 0.8082037738241963\n",
      "07/14 04:56:48 PM block_2-lambda: 0.9114039375020556\n",
      "07/14 04:56:50 PM block_2-lambda: 1.6098961078999348\n",
      "07/14 04:56:51 PM block_2-lambda: 0.5906226495290664\n",
      "07/14 04:56:53 PM block_2-lambda: 0.29696891801620195\n",
      "07/14 04:56:55 PM block_2-lambda: 0.5883146929972326\n",
      "07/14 04:56:57 PM block_2-lambda: 0.9690137623820495\n",
      "07/14 04:56:59 PM block_2-lambda: 1.272688825400081\n",
      "07/14 04:57:00 PM block_2-lambda: 1.2011779956462967\n",
      "07/14 04:57:02 PM block_2-lambda: 0.9004670741920261\n",
      "07/14 04:57:04 PM block_2-lambda: 0.9782412166191727\n",
      "07/14 04:57:06 PM block_2-lambda: 2.3175944976396217\n",
      "07/14 04:57:07 PM block_2-lambda: 1.296935328516036\n",
      "07/14 04:57:09 PM block_2-lambda: 1.0595995952421957\n",
      "07/14 04:57:11 PM block_2-lambda: 1.3569094537782496\n",
      "07/14 04:57:13 PM block_2-lambda: 1.094207299716179\n",
      "07/14 04:57:15 PM block_2-lambda: 1.0046366376077176\n",
      "07/14 04:57:16 PM block_2-lambda: 0.6148996666542564\n",
      "07/14 04:57:18 PM block_2-lambda: 1.22402781367288\n",
      "07/14 04:57:20 PM block_2-lambda: 1.2309631483274068\n",
      "07/14 04:57:20 PM block_id: 3\n",
      "07/14 04:57:22 PM block_3-lambda: -4.313181819566968e-05\n",
      "07/14 04:57:23 PM block_3-lambda: -0.02816857099393671\n",
      "07/14 04:57:25 PM block_3-lambda: -0.1685807892013441\n",
      "07/14 04:57:27 PM block_3-lambda: -0.11298591498672829\n",
      "07/14 04:57:29 PM block_3-lambda: 0.1898545965703938\n",
      "07/14 04:57:30 PM block_3-lambda: 0.9737089940252784\n",
      "07/14 04:57:32 PM block_3-lambda: 1.8109882467602472\n",
      "07/14 04:57:34 PM block_3-lambda: 2.5215299711382437\n",
      "07/14 04:57:35 PM block_3-lambda: 1.0593824282875814\n",
      "07/14 04:57:37 PM block_3-lambda: 1.901983163633091\n",
      "07/14 04:57:39 PM block_3-lambda: 1.217996389625254\n",
      "07/14 04:57:40 PM block_3-lambda: 0.989604562280499\n",
      "07/14 04:57:42 PM block_3-lambda: 1.643996316220325\n",
      "07/14 04:57:44 PM block_3-lambda: 1.0916181592659118\n",
      "07/14 04:57:46 PM block_3-lambda: 1.0793064703175705\n",
      "07/14 04:57:47 PM block_3-lambda: 1.5353157651060547\n",
      "07/14 04:57:49 PM block_3-lambda: 2.687841671250073\n",
      "07/14 04:57:51 PM block_3-lambda: 1.9833799078232808\n",
      "07/14 04:57:52 PM block_3-lambda: 2.227774459344576\n",
      "07/14 04:57:54 PM block_3-lambda: 1.034991117461134\n",
      "07/14 04:57:56 PM block_3-lambda: 0.0859809833553824\n",
      "07/14 04:57:58 PM block_3-lambda: 0.12414949203203915\n",
      "07/14 04:57:59 PM block_3-lambda: 0.06608344033341312\n",
      "07/14 04:58:01 PM block_3-lambda: -0.08169201964761008\n",
      "07/14 04:58:03 PM block_3-lambda: 0.36259618729488874\n",
      "07/14 04:58:04 PM block_3-lambda: 0.4997509485824026\n",
      "07/14 04:58:06 PM block_3-lambda: 0.27439147321094115\n",
      "07/14 04:58:08 PM block_3-lambda: 0.7916996206070105\n",
      "07/14 04:58:09 PM block_3-lambda: 2.3305422520026897\n",
      "07/14 04:58:11 PM block_3-lambda: 1.1776653455302193\n",
      "07/14 04:58:13 PM block_3-lambda: 0.8998606305640422\n",
      "07/14 04:58:15 PM block_3-lambda: 0.55775250374762\n",
      "07/14 04:58:16 PM block_3-lambda: 0.5567699883391516\n",
      "07/14 04:58:16 PM block_id: 4\n",
      "07/14 04:58:18 PM block_4-lambda: -8.202645222559169e-06\n",
      "07/14 04:58:20 PM block_4-lambda: -0.026083140328061215\n",
      "07/14 04:58:21 PM block_4-lambda: -0.1495689889057772\n",
      "07/14 04:58:23 PM block_4-lambda: -0.34444104327247677\n",
      "07/14 04:58:25 PM block_4-lambda: 0.029571086199656378\n",
      "07/14 04:58:26 PM block_4-lambda: 1.1252152433229208\n",
      "07/14 04:58:28 PM block_4-lambda: 1.4565939039476377\n",
      "07/14 04:58:30 PM block_4-lambda: 0.7230415384388293\n",
      "07/14 04:58:31 PM block_4-lambda: 1.4019799837521287\n",
      "07/14 04:58:33 PM block_4-lambda: 2.3645671567447337\n",
      "07/14 04:58:34 PM block_4-lambda: 1.9218463560891086\n",
      "07/14 04:58:36 PM block_4-lambda: 1.0614101823457234\n",
      "07/14 04:58:38 PM block_4-lambda: 3.92770902160566\n",
      "07/14 04:58:39 PM block_4-lambda: 3.1273144251449025\n",
      "07/14 04:58:41 PM block_4-lambda: 2.493515077104012\n",
      "07/14 04:58:43 PM block_4-lambda: 2.3101836976189736\n",
      "07/14 04:58:44 PM block_4-lambda: 2.0790577436689603\n",
      "07/14 04:58:46 PM block_4-lambda: 1.4999962455277525\n",
      "07/14 04:58:48 PM block_4-lambda: 2.1422351261228583\n",
      "07/14 04:58:49 PM block_4-lambda: 3.3693800975169204\n",
      "07/14 04:58:51 PM block_4-lambda: 2.653834610957874\n",
      "07/14 04:58:53 PM block_4-lambda: 1.728982471496846\n",
      "07/14 04:58:54 PM block_4-lambda: 2.215834024175261\n",
      "07/14 04:58:56 PM block_4-lambda: 2.3636797522539394\n",
      "07/14 04:58:58 PM block_4-lambda: 3.637585747577951\n",
      "07/14 04:58:59 PM block_4-lambda: 1.7793113147288144\n",
      "07/14 04:59:01 PM block_4-lambda: 2.246377833641533\n",
      "07/14 04:59:02 PM block_4-lambda: 2.8534786727132606\n",
      "07/14 04:59:04 PM block_4-lambda: 2.510012270985758\n",
      "07/14 04:59:06 PM block_4-lambda: 3.118897911930987\n",
      "07/14 04:59:07 PM block_4-lambda: 3.7588180847132278\n",
      "07/14 04:59:09 PM block_4-lambda: 6.185647917412802\n",
      "07/14 04:59:11 PM block_4-lambda: 4.072325082706883\n",
      "07/14 04:59:12 PM block_4-lambda: 2.497104131301346\n",
      "07/14 04:59:14 PM block_4-lambda: 1.7099022935000292\n",
      "07/14 04:59:16 PM block_4-lambda: 3.1237358991729764\n",
      "07/14 04:59:17 PM block_4-lambda: 3.331372846902957\n",
      "07/14 04:59:19 PM block_4-lambda: 1.7187579586246309\n",
      "07/14 04:59:21 PM block_4-lambda: 3.8874498014212517\n",
      "07/14 04:59:22 PM block_4-lambda: 1.1604501802089575\n",
      "07/14 04:59:24 PM block_4-lambda: 1.74838313581288\n",
      "07/14 04:59:26 PM block_4-lambda: 2.0579470457242754\n",
      "07/14 04:59:27 PM block_4-lambda: 2.1575622594282646\n",
      "07/14 04:59:29 PM block_4-lambda: 2.449280648827622\n",
      "07/14 04:59:30 PM block_4-lambda: 0.3287640695278581\n",
      "07/14 04:59:32 PM block_4-lambda: 0.3059475760113606\n",
      "07/14 04:59:34 PM block_4-lambda: 1.7011069426159038\n",
      "07/14 04:59:35 PM block_4-lambda: 0.8719001621018374\n",
      "07/14 04:59:37 PM block_4-lambda: 0.0708977056098896\n",
      "07/14 04:59:39 PM block_4-lambda: 0.3399398923268751\n",
      "07/14 04:59:40 PM block_4-lambda: 0.6301561805494011\n",
      "07/14 04:59:42 PM block_4-lambda: 0.5331065526218836\n",
      "07/14 04:59:44 PM block_4-lambda: 1.389733873156968\n",
      "07/14 04:59:45 PM block_4-lambda: 1.3349993244805065\n",
      "07/14 04:59:47 PM block_4-lambda: 0.7342590057226722\n",
      "07/14 04:59:49 PM block_4-lambda: 2.342985900657635\n",
      "07/14 04:59:50 PM block_4-lambda: 2.061629247949801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 04:59:52 PM block_4-lambda: 2.484659768868407\n",
      "07/14 04:59:54 PM block_4-lambda: 2.0688036090100024\n",
      "07/14 04:59:55 PM block_4-lambda: 3.3194995068650592\n",
      "07/14 04:59:57 PM block_4-lambda: 3.1239853645818103\n",
      "07/14 04:59:59 PM block_4-lambda: 3.032537912460896\n",
      "07/14 05:00:00 PM block_4-lambda: 2.9746640789454446\n",
      "07/14 05:00:02 PM block_4-lambda: 2.797765980518543\n",
      "07/14 05:00:03 PM block_4-lambda: 3.29172497757024\n",
      "07/14 05:00:05 PM block_4-lambda: 3.2816714145275405\n",
      "07/14 05:00:05 PM block_id: 5\n",
      "07/14 05:00:07 PM block_5-lambda: -3.770498815697824e-05\n",
      "07/14 05:00:08 PM block_5-lambda: 0.37657312030276974\n",
      "07/14 05:00:10 PM block_5-lambda: 4.594871959077337\n",
      "07/14 05:00:11 PM block_5-lambda: 2.691821162010017\n",
      "07/14 05:00:13 PM block_5-lambda: 2.6442498216126036\n",
      "07/14 05:00:15 PM block_5-lambda: 3.7548384155087855\n",
      "07/14 05:00:16 PM block_5-lambda: 3.487251254079384\n",
      "07/14 05:00:18 PM block_5-lambda: 7.107801262279265\n",
      "07/14 05:00:19 PM block_5-lambda: 1.6374033273360753\n",
      "07/14 05:00:21 PM block_5-lambda: 1.964438024312763\n",
      "07/14 05:00:23 PM block_5-lambda: 1.3832566055299635\n",
      "07/14 05:00:24 PM block_5-lambda: 1.7600798157973117\n",
      "07/14 05:00:26 PM block_5-lambda: 5.728929573409725\n",
      "07/14 05:00:27 PM block_5-lambda: 3.622442590550447\n",
      "07/14 05:00:29 PM block_5-lambda: 2.9787451046250073\n",
      "07/14 05:00:30 PM block_5-lambda: 2.5775661832086523\n",
      "07/14 05:00:32 PM block_5-lambda: 5.200660338862962\n",
      "07/14 05:00:34 PM block_5-lambda: 3.88819391497979\n",
      "07/14 05:00:35 PM block_5-lambda: 4.845510105154916\n",
      "07/14 05:00:37 PM block_5-lambda: 1.9637438752137906\n",
      "07/14 05:00:38 PM block_5-lambda: 2.283240898131432\n",
      "07/14 05:00:40 PM block_5-lambda: 3.3861049865786894\n",
      "07/14 05:00:42 PM block_5-lambda: 3.6964510187267936\n",
      "07/14 05:00:43 PM block_5-lambda: 5.4100278413389145\n",
      "07/14 05:00:45 PM block_5-lambda: 3.1800697566668004\n",
      "07/14 05:00:46 PM block_5-lambda: 3.2115602141973523\n",
      "07/14 05:00:46 PM block_id: 6\n",
      "07/14 05:00:48 PM block_6-lambda: -1.0872012746613244e-05\n",
      "07/14 05:00:49 PM block_6-lambda: 0.06643930327444798\n",
      "07/14 05:00:51 PM block_6-lambda: 1.9178775719990717\n",
      "07/14 05:00:52 PM block_6-lambda: 8.72627002232926\n",
      "07/14 05:00:54 PM block_6-lambda: 10.449083132181178\n",
      "07/14 05:00:56 PM block_6-lambda: 4.579902250102327\n",
      "07/14 05:00:57 PM block_6-lambda: 3.8162693616563486\n",
      "07/14 05:00:59 PM block_6-lambda: 4.9301409774350216\n",
      "07/14 05:01:00 PM block_6-lambda: 9.140417576115\n",
      "07/14 05:01:02 PM block_6-lambda: 4.721778474374342\n",
      "07/14 05:01:03 PM block_6-lambda: 7.145385956320898\n",
      "07/14 05:01:05 PM block_6-lambda: 2.8573546656641033\n",
      "07/14 05:01:06 PM block_6-lambda: 3.824154824042875\n",
      "07/14 05:01:08 PM block_6-lambda: 3.4519199571641836\n",
      "07/14 05:01:09 PM block_6-lambda: 5.181572487752711\n",
      "07/14 05:01:11 PM block_6-lambda: 7.22237405073237\n",
      "07/14 05:01:12 PM block_6-lambda: 5.880258002764662\n",
      "07/14 05:01:14 PM block_6-lambda: 10.579374739613787\n",
      "07/14 05:01:15 PM block_6-lambda: 7.822664912409732\n",
      "07/14 05:01:17 PM block_6-lambda: 5.061398326493246\n",
      "07/14 05:01:18 PM block_6-lambda: 4.06166623592544\n",
      "07/14 05:01:20 PM block_6-lambda: 4.111365883855872\n",
      "07/14 05:01:21 PM block_6-lambda: 5.7725995817375155\n",
      "07/14 05:01:23 PM block_6-lambda: 8.364772874700327\n",
      "07/14 05:01:24 PM block_6-lambda: 6.141346572449494\n",
      "07/14 05:01:26 PM block_6-lambda: 7.782412830005262\n",
      "07/14 05:01:27 PM block_6-lambda: 8.726473449057492\n",
      "07/14 05:01:29 PM block_6-lambda: 7.976998704007571\n",
      "07/14 05:01:31 PM block_6-lambda: 5.185835526820693\n",
      "07/14 05:01:32 PM block_6-lambda: 6.348983163290478\n",
      "07/14 05:01:34 PM block_6-lambda: 8.916264876275434\n",
      "07/14 05:01:35 PM block_6-lambda: 8.54547219783322\n",
      "07/14 05:01:37 PM block_6-lambda: 2.5886395565599964\n",
      "07/14 05:01:38 PM block_6-lambda: 2.630455704993385\n",
      "07/14 05:01:40 PM block_6-lambda: 4.211533561727064\n",
      "07/14 05:01:41 PM block_6-lambda: 1.7900499262010656\n",
      "07/14 05:01:43 PM block_6-lambda: 0.7079340703110153\n",
      "07/14 05:01:44 PM block_6-lambda: 4.487063287782496\n",
      "07/14 05:01:46 PM block_6-lambda: 6.130244469533899\n",
      "07/14 05:01:47 PM block_6-lambda: 4.134106493849403\n",
      "07/14 05:01:49 PM block_6-lambda: 10.108829445203776\n",
      "07/14 05:01:50 PM block_6-lambda: 4.731312050148557\n",
      "07/14 05:01:52 PM block_6-lambda: 3.935895341416574\n",
      "07/14 05:01:54 PM block_6-lambda: 7.456681670089755\n",
      "07/14 05:01:55 PM block_6-lambda: 6.700174070466904\n",
      "07/14 05:01:57 PM block_6-lambda: 2.713946316928393\n",
      "07/14 05:01:58 PM block_6-lambda: 4.311911090328434\n",
      "07/14 05:02:00 PM block_6-lambda: 6.175348100962241\n",
      "07/14 05:02:01 PM block_6-lambda: 6.467887870387966\n",
      "07/14 05:02:03 PM block_6-lambda: 5.713784631937236\n",
      "07/14 05:02:04 PM block_6-lambda: 7.806571359983481\n",
      "07/14 05:02:06 PM block_6-lambda: 4.756341389279214\n",
      "07/14 05:02:07 PM block_6-lambda: 9.446756815494897\n",
      "07/14 05:02:09 PM block_6-lambda: 8.918440471600544\n",
      "07/14 05:02:10 PM block_6-lambda: 6.707582372264574\n",
      "07/14 05:02:12 PM block_6-lambda: 4.848761363916683\n",
      "07/14 05:02:13 PM block_6-lambda: 6.070873843565445\n",
      "07/14 05:02:15 PM block_6-lambda: 4.219175268928707\n",
      "07/14 05:02:16 PM block_6-lambda: 2.9007354154599057\n",
      "07/14 05:02:18 PM block_6-lambda: 5.35002623562394\n",
      "07/14 05:02:20 PM block_6-lambda: 5.306752017193713\n",
      "07/14 05:02:20 PM block_id: 7\n",
      "07/14 05:02:21 PM block_7-lambda: 2.079493225791861e-05\n",
      "07/14 05:02:22 PM block_7-lambda: 1.5108526303689809\n",
      "07/14 05:02:24 PM block_7-lambda: 6.907298882486332\n",
      "07/14 05:02:25 PM block_7-lambda: 3.240599558097189\n",
      "07/14 05:02:27 PM block_7-lambda: 5.049814066542838\n",
      "07/14 05:02:28 PM block_7-lambda: 7.802876131309569\n",
      "07/14 05:02:30 PM block_7-lambda: 11.441737043273447\n",
      "07/14 05:02:31 PM block_7-lambda: 8.181926507362077\n",
      "07/14 05:02:33 PM block_7-lambda: 3.155373394970252\n",
      "07/14 05:02:34 PM block_7-lambda: 6.882996883131359\n",
      "07/14 05:02:36 PM block_7-lambda: 10.015304542231902\n",
      "07/14 05:02:37 PM block_7-lambda: 5.825935214768375\n",
      "07/14 05:02:39 PM block_7-lambda: 7.5324856068095105\n",
      "07/14 05:02:40 PM block_7-lambda: 5.833362431682881\n",
      "07/14 05:02:41 PM block_7-lambda: 8.313969725991477\n",
      "07/14 05:02:43 PM block_7-lambda: 3.5816548177616285\n",
      "07/14 05:02:44 PM block_7-lambda: 6.170556509289849\n",
      "07/14 05:02:46 PM block_7-lambda: 14.17019482370483\n",
      "07/14 05:02:47 PM block_7-lambda: 5.636446072530807\n",
      "07/14 05:02:49 PM block_7-lambda: 5.040176279181528\n",
      "07/14 05:02:50 PM block_7-lambda: 6.466094860067535\n",
      "07/14 05:02:52 PM block_7-lambda: 6.98711924797721\n",
      "07/14 05:02:53 PM block_7-lambda: 5.3866944387215305\n",
      "07/14 05:02:55 PM block_7-lambda: 7.983885947869767\n",
      "07/14 05:02:56 PM block_7-lambda: 7.7177409748768415\n",
      "07/14 05:02:58 PM block_7-lambda: 8.217379146536222\n",
      "07/14 05:02:59 PM block_7-lambda: 4.232709213469184\n",
      "07/14 05:03:00 PM block_7-lambda: 7.6055443533651035\n",
      "07/14 05:03:02 PM block_7-lambda: 9.52354005562215\n",
      "07/14 05:03:03 PM block_7-lambda: 9.088327485683326\n",
      "07/14 05:03:05 PM block_7-lambda: 8.063355134587693\n",
      "07/14 05:03:06 PM block_7-lambda: 6.835870404868582\n",
      "07/14 05:03:08 PM block_7-lambda: 6.130712707897834\n",
      "07/14 05:03:09 PM block_7-lambda: 13.10769345325108\n",
      "07/14 05:03:11 PM block_7-lambda: 9.155758806535784\n",
      "07/14 05:03:12 PM block_7-lambda: 4.3108900309083\n",
      "07/14 05:03:14 PM block_7-lambda: 6.16390124327564\n",
      "07/14 05:03:15 PM block_7-lambda: 2.497444424959891\n",
      "07/14 05:03:16 PM block_7-lambda: 2.803462642687076\n",
      "07/14 05:03:18 PM block_7-lambda: 7.3200281593983885\n",
      "07/14 05:03:19 PM block_7-lambda: 7.272688261515466\n",
      "07/14 05:03:19 PM block_id: 8\n",
      "07/14 05:03:21 PM block_8-lambda: 8.052264427026242e-06\n",
      "07/14 05:03:22 PM block_8-lambda: 0.013541727787624979\n",
      "07/14 05:03:24 PM block_8-lambda: 0.0632958082605727\n",
      "07/14 05:03:25 PM block_8-lambda: 5.740064153224038\n",
      "07/14 05:03:26 PM block_8-lambda: 4.790361832908797\n",
      "07/14 05:03:28 PM block_8-lambda: 5.239746108025559\n",
      "07/14 05:03:29 PM block_8-lambda: 5.658091033303853\n",
      "07/14 05:03:31 PM block_8-lambda: 4.695003948048839\n",
      "07/14 05:03:32 PM block_8-lambda: 5.346594034140743\n",
      "07/14 05:03:33 PM block_8-lambda: 6.213471697389194\n",
      "07/14 05:03:35 PM block_8-lambda: 6.075510545413183\n",
      "07/14 05:03:36 PM block_8-lambda: 2.974696377399664\n",
      "07/14 05:03:38 PM block_8-lambda: 2.3961398771890714\n",
      "07/14 05:03:39 PM block_8-lambda: 5.1755449894840515\n",
      "07/14 05:03:40 PM block_8-lambda: 5.01457698832282\n",
      "07/14 05:03:42 PM block_8-lambda: 6.570916013569319\n",
      "07/14 05:03:43 PM block_8-lambda: 7.56588684802947\n",
      "07/14 05:03:45 PM block_8-lambda: 3.062321369919271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 05:03:46 PM block_8-lambda: 4.797620241327769\n",
      "07/14 05:03:47 PM block_8-lambda: 7.375163940529616\n",
      "07/14 05:03:49 PM block_8-lambda: 3.6267834314197533\n",
      "07/14 05:03:50 PM block_8-lambda: 4.537779355576102\n",
      "07/14 05:03:52 PM block_8-lambda: 4.096660272738569\n",
      "07/14 05:03:53 PM block_8-lambda: 1.4401225845181667\n",
      "07/14 05:03:54 PM block_8-lambda: 3.7027868690887757\n",
      "07/14 05:03:56 PM block_8-lambda: 4.286588388442324\n",
      "07/14 05:03:57 PM block_8-lambda: 2.95772452115204\n",
      "07/14 05:03:59 PM block_8-lambda: 3.337845028861756\n",
      "07/14 05:04:00 PM block_8-lambda: 4.58247684732597\n",
      "07/14 05:04:01 PM block_8-lambda: 4.364462281344104\n",
      "07/14 05:04:03 PM block_8-lambda: 5.475176857056192\n",
      "07/14 05:04:04 PM block_8-lambda: 3.665441290675067\n",
      "07/14 05:04:06 PM block_8-lambda: 4.0032313729068605\n",
      "07/14 05:04:07 PM block_8-lambda: 5.58618396754126\n",
      "07/14 05:04:08 PM block_8-lambda: 7.347249510748012\n",
      "07/14 05:04:10 PM block_8-lambda: 4.925340463537707\n",
      "07/14 05:04:11 PM block_8-lambda: 3.0802479042336057\n",
      "07/14 05:04:13 PM block_8-lambda: 4.945147802865709\n",
      "07/14 05:04:14 PM block_8-lambda: 2.9647354270516604\n",
      "07/14 05:04:15 PM block_8-lambda: 6.155545044302201\n",
      "07/14 05:04:17 PM block_8-lambda: 4.230052531776254\n",
      "07/14 05:04:18 PM block_8-lambda: 3.954288329649858\n",
      "07/14 05:04:20 PM block_8-lambda: 4.93721665868758\n",
      "07/14 05:04:21 PM block_8-lambda: 1.8969663750036545\n",
      "07/14 05:04:22 PM block_8-lambda: 7.350480069947959\n",
      "07/14 05:04:24 PM block_8-lambda: 4.230820200008588\n",
      "07/14 05:04:25 PM block_8-lambda: 3.322044839190957\n",
      "07/14 05:04:27 PM block_8-lambda: 3.0758074913341638\n",
      "07/14 05:04:28 PM block_8-lambda: 5.362666887005174\n",
      "07/14 05:04:29 PM block_8-lambda: 5.3292413773334255\n",
      "07/14 05:04:29 PM block_id: 9\n",
      "07/14 05:04:31 PM block_9-lambda: 7.4309965201552575e-06\n",
      "07/14 05:04:32 PM block_9-lambda: 0.031044477329604345\n",
      "07/14 05:04:33 PM block_9-lambda: 0.9460777556627148\n",
      "07/14 05:04:35 PM block_9-lambda: 1.531513112844075\n",
      "07/14 05:04:36 PM block_9-lambda: 3.389170306173072\n",
      "07/14 05:04:37 PM block_9-lambda: 1.4101694263417655\n",
      "07/14 05:04:39 PM block_9-lambda: 2.0203859063564384\n",
      "07/14 05:04:40 PM block_9-lambda: 2.686206405866273\n",
      "07/14 05:04:41 PM block_9-lambda: 2.872849715242552\n",
      "07/14 05:04:43 PM block_9-lambda: 1.5481334334297523\n",
      "07/14 05:04:44 PM block_9-lambda: 1.622783369578028\n",
      "07/14 05:04:45 PM block_9-lambda: 2.991556884280256\n",
      "07/14 05:04:47 PM block_9-lambda: 1.628343343260748\n",
      "07/14 05:04:48 PM block_9-lambda: 2.1132127344503746\n",
      "07/14 05:04:49 PM block_9-lambda: 0.808008377098393\n",
      "07/14 05:04:51 PM block_9-lambda: 2.2220107020446256\n",
      "07/14 05:04:52 PM block_9-lambda: 1.8225539484828162\n",
      "07/14 05:04:53 PM block_9-lambda: 2.284148109961554\n",
      "07/14 05:04:55 PM block_9-lambda: 1.1143128198010923\n",
      "07/14 05:04:56 PM block_9-lambda: 1.5253983552156727\n",
      "07/14 05:04:57 PM block_9-lambda: 2.368458674366942\n",
      "07/14 05:04:59 PM block_9-lambda: 1.761259690821066\n",
      "07/14 05:05:00 PM block_9-lambda: 1.3259350577372164\n",
      "07/14 05:05:01 PM block_9-lambda: 1.771727601989168\n",
      "07/14 05:05:03 PM block_9-lambda: 1.5960457812637043\n",
      "07/14 05:05:04 PM block_9-lambda: 2.2294887756411894\n",
      "07/14 05:05:05 PM block_9-lambda: 2.8620491835293387\n",
      "07/14 05:05:07 PM block_9-lambda: 2.17320738082991\n",
      "07/14 05:05:08 PM block_9-lambda: 1.779372521191783\n",
      "07/14 05:05:09 PM block_9-lambda: 2.3272476312277983\n",
      "07/14 05:05:11 PM block_9-lambda: 2.0846089735712563\n",
      "07/14 05:05:12 PM block_9-lambda: 1.755491650853153\n",
      "07/14 05:05:13 PM block_9-lambda: 3.2696660255607894\n",
      "07/14 05:05:15 PM block_9-lambda: 2.01903026350171\n",
      "07/14 05:05:16 PM block_9-lambda: 2.133734565550173\n",
      "07/14 05:05:17 PM block_9-lambda: 2.3008899512506757\n",
      "07/14 05:05:19 PM block_9-lambda: 2.7210817770879316\n",
      "07/14 05:05:20 PM block_9-lambda: 3.7403861955792816\n",
      "07/14 05:05:21 PM block_9-lambda: 1.9570479238539351\n",
      "07/14 05:05:23 PM block_9-lambda: 2.3251275321417086\n",
      "07/14 05:05:24 PM block_9-lambda: 1.2325882423747954\n",
      "07/14 05:05:25 PM block_9-lambda: 2.7014892849360637\n",
      "07/14 05:05:27 PM block_9-lambda: 1.9891659706855374\n",
      "07/14 05:05:28 PM block_9-lambda: 2.2136373723993357\n",
      "07/14 05:05:29 PM block_9-lambda: 2.400929684416479\n",
      "07/14 05:05:31 PM block_9-lambda: 2.8578054164671896\n",
      "07/14 05:05:32 PM block_9-lambda: 1.2135290316065463\n",
      "07/14 05:05:33 PM block_9-lambda: 1.585539504528436\n",
      "07/14 05:05:35 PM block_9-lambda: 1.2479524921358796\n",
      "07/14 05:05:36 PM block_9-lambda: 1.7059044229567448\n",
      "07/14 05:05:37 PM block_9-lambda: 3.595314387229015\n",
      "07/14 05:05:39 PM block_9-lambda: 0.9910271218221461\n",
      "07/14 05:05:40 PM block_9-lambda: 2.2351954307016357\n",
      "07/14 05:05:41 PM block_9-lambda: 2.244386571483324\n",
      "07/14 05:05:41 PM block_id: 10\n",
      "07/14 05:05:43 PM block_10-lambda: -6.58155948362801e-06\n",
      "07/14 05:05:44 PM block_10-lambda: 0.005273012275124778\n",
      "07/14 05:05:45 PM block_10-lambda: 0.03402687320791759\n",
      "07/14 05:05:47 PM block_10-lambda: -0.016903866105519628\n",
      "07/14 05:05:48 PM block_10-lambda: 0.08922079378729632\n",
      "07/14 05:05:49 PM block_10-lambda: 0.750541129372661\n",
      "07/14 05:05:50 PM block_10-lambda: 0.744774115460614\n",
      "07/14 05:05:50 PM block_id: 11\n",
      "07/14 05:05:52 PM block_11-lambda: -2.0783735485769238e-07\n",
      "07/14 05:05:53 PM block_11-lambda: 0.00726725396852356\n",
      "07/14 05:05:54 PM block_11-lambda: 0.2648983597267498\n",
      "07/14 05:05:55 PM block_11-lambda: 0.7374337564057292\n",
      "07/14 05:05:56 PM block_11-lambda: 0.5973998377468416\n",
      "07/14 05:05:58 PM block_11-lambda: 0.6836323832339145\n",
      "07/14 05:05:59 PM block_11-lambda: 0.4732985145766029\n",
      "07/14 05:06:00 PM block_11-lambda: 0.22787030099247116\n",
      "07/14 05:06:01 PM block_11-lambda: 0.3647986831281383\n",
      "07/14 05:06:02 PM block_11-lambda: 0.6607506236421087\n",
      "07/14 05:06:04 PM block_11-lambda: 1.0687939480248563\n",
      "07/14 05:06:05 PM block_11-lambda: 0.42345124843482757\n",
      "07/14 05:06:06 PM block_11-lambda: 0.7220257431314\n",
      "07/14 05:06:07 PM block_11-lambda: 0.4133268875373677\n",
      "07/14 05:06:08 PM block_11-lambda: 0.3068830936000495\n",
      "07/14 05:06:10 PM block_11-lambda: 1.1220333994710505\n",
      "07/14 05:06:11 PM block_11-lambda: 0.580916607147099\n",
      "07/14 05:06:12 PM block_11-lambda: 0.6251706197071933\n",
      "07/14 05:06:13 PM block_11-lambda: -0.10349787601796162\n",
      "07/14 05:06:14 PM block_11-lambda: 0.08348763971883028\n",
      "07/14 05:06:16 PM block_11-lambda: 0.26385082360415857\n",
      "07/14 05:06:17 PM block_11-lambda: 0.4841778741470067\n",
      "07/14 05:06:18 PM block_11-lambda: -0.06251722703188041\n",
      "07/14 05:06:19 PM block_11-lambda: -0.45269169928441755\n",
      "07/14 05:06:20 PM block_11-lambda: -0.17689285661975984\n",
      "07/14 05:06:22 PM block_11-lambda: 0.039707294138896225\n",
      "07/14 05:06:23 PM block_11-lambda: 0.596552315601451\n",
      "07/14 05:06:24 PM block_11-lambda: 1.0609456913162567\n",
      "07/14 05:06:25 PM block_11-lambda: 0.6029043151905433\n",
      "07/14 05:06:26 PM block_11-lambda: 1.171329495168237\n",
      "07/14 05:06:28 PM block_11-lambda: 0.9348212090337112\n",
      "07/14 05:06:29 PM block_11-lambda: 0.7756707543114475\n",
      "07/14 05:06:30 PM block_11-lambda: 1.111180137408545\n",
      "07/14 05:06:31 PM block_11-lambda: 1.092725853490043\n",
      "07/14 05:06:32 PM block_11-lambda: 0.8683476890266855\n",
      "07/14 05:06:34 PM block_11-lambda: 0.709547966966126\n",
      "07/14 05:06:35 PM block_11-lambda: 0.9494033365580871\n",
      "07/14 05:06:36 PM block_11-lambda: 0.9122561884266551\n",
      "07/14 05:06:37 PM block_11-lambda: 0.4312515035733439\n",
      "07/14 05:06:38 PM block_11-lambda: 0.7143702957033762\n",
      "07/14 05:06:40 PM block_11-lambda: 0.8551938312679072\n",
      "07/14 05:06:41 PM block_11-lambda: 0.7302833961305695\n",
      "07/14 05:06:42 PM block_11-lambda: 0.7610040440948062\n",
      "07/14 05:06:43 PM block_11-lambda: 0.9135012849145933\n",
      "07/14 05:06:45 PM block_11-lambda: 0.9827183890852952\n",
      "07/14 05:06:46 PM block_11-lambda: 1.0442671086018356\n",
      "07/14 05:06:47 PM block_11-lambda: 0.5238644659358874\n",
      "07/14 05:06:48 PM block_11-lambda: 0.649134109848606\n",
      "07/14 05:06:49 PM block_11-lambda: 0.4483747699779037\n",
      "07/14 05:06:50 PM block_11-lambda: 0.30962756998621777\n",
      "07/14 05:06:52 PM block_11-lambda: 0.030569235019106123\n",
      "07/14 05:06:53 PM block_11-lambda: 0.39192447744884096\n",
      "07/14 05:06:54 PM block_11-lambda: 0.42562461320370515\n",
      "07/14 05:06:55 PM block_11-lambda: 0.33805103500521455\n",
      "07/14 05:06:56 PM block_11-lambda: 0.11195438310509187\n",
      "07/14 05:06:58 PM block_11-lambda: -0.6078020367283888\n",
      "07/14 05:06:59 PM block_11-lambda: -0.8888466792306821\n",
      "07/14 05:07:00 PM block_11-lambda: -0.6845991509153946\n",
      "07/14 05:07:01 PM block_11-lambda: -1.115362876452224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/14 05:07:02 PM block_11-lambda: -1.1126199168442927\n"
     ]
    }
   ],
   "source": [
    "loss_fct = CrossEntropyLoss()\n",
    "\n",
    "for module in student_model.modules():\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "block_id = 0\n",
    "\n",
    "for block_id in range(layer_num):\n",
    "    logger.info(f'block_id: {block_id}')\n",
    "    model_block = student_model.bert.encoder.layer[block_id]\n",
    "    \n",
    "    v = [\n",
    "            torch.randn(p.size()).to(device) for p in model_block.parameters()\n",
    "        ]\n",
    "    v = de_variable(v)\n",
    "\n",
    "    lambda_old, lambdas = 0., 1.\n",
    "    i = 0\n",
    "    while (abs((lambdas - lambda_old) / lambdas) >= 0.01):\n",
    "\n",
    "        lambda_old = lambdas\n",
    "\n",
    "        acc_Hv = [\n",
    "            torch.zeros(p.size()).cuda() for p in model_block.parameters()\n",
    "        ]\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step < percentage_index:\n",
    "                \n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, _ = batch\n",
    "                \n",
    "                logits, _, _, _, _ = student_model(input_ids, segment_ids, input_mask, teacher_outputs=None)\n",
    "\n",
    "                if output_mode == \"classification\":\n",
    "                    loss_fct = CrossEntropyLoss()\n",
    "                    loss = loss_fct(\n",
    "                        logits.view(-1, num_labels), label_ids.view(-1))\n",
    "                elif output_mode == \"regression\":\n",
    "                    loss_fct = MSELoss()\n",
    "                    loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "                    \n",
    "                loss.backward(create_graph=True)\n",
    "                grads = [param.grad for param in model_block.parameters()]\n",
    "                params = model_block.parameters()\n",
    "\n",
    "                Hv = torch.autograd.grad(\n",
    "                    grads,\n",
    "                    params,\n",
    "                    grad_outputs=v,\n",
    "                    only_inputs=True,\n",
    "                    retain_graph=True)\n",
    "                acc_Hv = [\n",
    "                    acc_Hv_p + Hv_p for acc_Hv_p, Hv_p in zip(acc_Hv, Hv)\n",
    "                ]\n",
    "                student_model.zero_grad()\n",
    "        # calculate raylay quotients\n",
    "        lambdas = group_product(acc_Hv, v).item() / percentage_index\n",
    "\n",
    "        v = de_variable(acc_Hv)\n",
    "        logger.info(f'block_{block_id}-lambda: {lambdas}')\n",
    "        writer.writerow([f'{block_id}', f'{i}', f'{lambdas}'])\n",
    "        csv_file.flush()\n",
    "\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
